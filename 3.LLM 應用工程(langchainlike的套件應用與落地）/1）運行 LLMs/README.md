3. ğŸ‘· **LLM æ‡‰ç”¨å·¥ç¨‹** å°ˆæ³¨åœ¨å‰µå»º LLM é©…å‹•çš„æ‡‰ç”¨ä»¥åŠéƒ¨ç½².


| åç¨± | æ•˜è¿° | æ–‡ç«  | é€£çµ |
|---------------------------------------|-------------------------------------------------------------------------|---------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------|
| Decoding Strategies in Large Language Models | å¾æ³¢æŸæœå°‹(beam search)åˆ°æ ¸æ¡æ¨£(nucleus sampling)çš„æ–‡æœ¬ç”ŸæˆæŒ‡å—| [Article](https://mlabonne.github.io/blog/posts/2022-06-07-Decoding_strategies.html) | <a href="https://colab.research.google.com/drive/19CJlOS5lI29g-B3dziNn93Enez1yiHk2?usp=sharing"><img src="../../img/colab.svg" alt="Open In Colab"></a> |
| Visualizing GPT-2's Loss Landscape | åŸºæ–¼æ¬Šé‡æ“¾å‹•çš„æå¤±æ™¯è§€ä¸‰ç¶­åœ–(3D plot of the loss landscape based on weight perturbations.)| [Tweet](https://twitter.com/maximelabonne/status/1667618081844219904) | <a href="https://colab.research.google.com/drive/1Fu1jikJzFxnSPzR_V2JJyDVWWJNXssaL?usp=sharing"><img src="../../img/colab.svg" alt="Open In Colab"></a> |
| Improve ChatGPT with Knowledge Graphs | ç”¨çŸ¥è­˜åœ–è­œå¢å¼· ChatGPT çš„ç­”æ¡ˆ | [Article](https://mlabonne.github.io/blog/posts/Article_Improve_ChatGPT_with_Knowledge_Graphs.html) | <a href="https://colab.research.google.com/drive/1mwhOSw9Y9bgEaIFKT4CLi0n18pXRM4cj?usp=sharing"><img src="../../img/colab.svg" alt="Open In Colab"></a> |
| Merge LLMs with mergekit | è¼•é¬†å‰µå»ºæ‚¨è‡ªå·±çš„æ¨¡å‹ï¼Œç„¡éœ€ GPUï¼| [Article](https://towardsdatascience.com/merge-large-language-models-with-mergekit-2118fb392b54) | <a href="https://colab.research.google.com/drive/1_JS7JKJAQozD48-LhYdegcuuZ2ddgXfr?usp=sharing"><img src="../img/colab.svg" alt="Open In Colab"></a> |


## ğŸ‘· LLM æ‡‰ç”¨å·¥ç¨‹

æœ¬èª²ç¨‹çš„é€™ä¸€éƒ¨åˆ†é‡é»æ˜¯å­¸ç¿’å¦‚ä½•å»ºç«‹å¯åœ¨ç”Ÿç”¢ä¸­ä½¿ç”¨çš„ç”± LLM æ”¯æ´çš„æ‡‰ç”¨ç¨‹åºï¼Œé‡é»ä¸»è¦åœ¨å¢å¼·æ¨¡å‹å’Œéƒ¨ç½²å®ƒå€‘ã€‚

![](../img/roadmap_engineer.png)


### 1. é‹è¡Œ LLMs


ç”±æ–¼ç¡¬é«”è¦æ±‚é«˜ï¼Œé‹è¡Œå¤§å‹èªè¨€æ¨¡å‹å¯èƒ½æœƒæœ‰å›°é›£ã€‚æ ¹æ“šæ‚¨çš„ä½¿ç”¨æ¡ˆä¾‹ï¼Œæ‚¨ä¹Ÿå¯èƒ½åªæƒ³é€šéAPIï¼ˆå¦‚GPT-4ï¼‰ç°¡å–®åœ°ä½¿ç”¨æ¨¡å‹ï¼Œæˆ–è€…åœ¨æœ¬åœ°é‹è¡Œå®ƒã€‚ç„¡è«–å“ªç¨®æƒ…æ³ï¼Œé¡å¤–çš„æç¤ºå’ŒæŒ‡å°æŠ€è¡“éƒ½å¯ä»¥æ”¹å–„æˆ–é™åˆ¶æ‚¨çš„æ‡‰ç”¨ç¨‹åºçš„è¼¸å‡ºã€‚

* **LLM APIs**: APIsæ˜¯éƒ¨ç½²LLMsçš„ä¾¿æ·æ–¹å¼ã€‚é€™å€‹é ˜åŸŸåˆ†åˆ¥æœ‰ç§æœ‰LLMs ([OpenAI](https://platform.openai.com/), [Google](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview), [Anthropic](https://docs.anthropic.com/claude/reference/getting-started-with-the-api), [Cohere](https://docs.cohere.com/docs), ç­‰.) å’Œé–‹æºLLMs ([OpenRouter](https://openrouter.ai/), [Hugging Face](https://huggingface.co/inference-api), [Together AI](https://www.together.ai/), ç­‰.).
* **é–‹æº LLMs**: [Hugging Face Hub](https://huggingface.co/models) æ˜¯å°‹æ‰¾LLMsçš„å¥½åœ°æ–¹ã€‚ æ‚¨å¯ä»¥ç›´æ¥åœ¨ [Hugging Face Spaces](https://huggingface.co/spaces)ä¸­é‹è¡Œä¸€äº›æ¨¡å‹ï¼Œ æˆ–è€…ä¸‹è¼‰ä¸¦åœ¨åƒ [LM Studio](https://lmstudio.ai/) é€™æ¨£çš„æ‡‰ç”¨ç¨‹åºä¸­æœ¬åœ°é‹è¡Œä»¥åŠé€šéCLIä½¿ç”¨ [llama.cpp](https://github.com/ggerganov/llama.cpp) æˆ– [Ollama](https://ollama.ai/)ã€‚
* **æç¤ºå·¥ç¨‹ Prompt engineering**: å¸¸è¦‹æŠ€è¡“åŒ…æ‹¬é›¶æç¤ºè©ã€å°‘é‡æç¤ºè©ã€æ€ç¶­éˆèˆ‡ReActã€‚å®ƒå€‘åœ¨æ›´å¤§çš„æ¨¡å‹ä¸Šå·¥ä½œå¾—æ›´å¥½ï¼Œä½†ä¹Ÿå¯ä»¥é©æ‡‰è¼ƒå°çš„æ¨¡å‹ã€‚
* **çµæ§‹åŒ–è¼¸å‡º Structuring outputs**: è¨±å¤šä»»å‹™éœ€è¦çµæ§‹åŒ–çš„è¼¸å‡ºï¼Œå¦‚åš´æ ¼çš„æ¨¡æ¿æˆ–JSONæ ¼å¼ã€‚åƒ [LMQL](https://lmql.ai/), [Outlines](https://github.com/outlines-dev/outlines), [Guidance](https://github.com/guidance-ai/guidance), ç­‰åº«å¯ä»¥ç”¨ä¾†æŒ‡å°ç”Ÿæˆä¸¦éµå¾ªçµ¦å®šçš„çµæ§‹ã€‚

ğŸ“š **åƒè€ƒè³‡æ–™**:
* [Run an LLM locally with LM Studio](https://www.kdnuggets.com/run-an-llm-locally-with-lm-studio) by Nisha Arya: é—œæ–¼å¦‚ä½•ä½¿ç”¨LM Studioçš„ç°¡çŸ­æŒ‡å—ã€‚
* [Prompt engineering guide](https://www.promptingguide.ai/) by DAIR.AI: å¸¶æœ‰ç¤ºä¾‹çš„æç¤ºæŠ€è¡“çš„è©³ç›¡åˆ—è¡¨ã€‚
* [Outlines - Quickstart](https://outlines-dev.github.io/outlines/quickstart/): Outlineså•Ÿç”¨çš„æŒ‡å°ç”ŸæˆæŠ€è¡“çš„åˆ—è¡¨ã€‚
* [LMQL - Overview](https://lmql.ai/docs/language/overview.html): å°LMQLèªè¨€çš„ä»‹ç´¹ã€‚
---
### 2. å»ºç«‹å‘é‡å„²å­˜

å‰µå»ºå‘é‡å„²å­˜æ˜¯å»ºç«‹æª¢ç´¢å¢å¼·ç”Ÿæˆï¼ˆRetrieval Augmented Generationï¼Œç°¡ç¨±RAGï¼‰æµç¨‹çš„ç¬¬ä¸€æ­¥ã€‚æ–‡ä»¶è¢«åŠ è¼‰ã€æ‹†åˆ†ï¼Œä¸¦ä½¿ç”¨ç›¸é—œçš„ç‰‡æ®µä¾†ç”¢ç”Ÿå‘é‡è¡¨ç¤ºï¼ˆåµŒå…¥ï¼‰ï¼Œé€™äº›å‘é‡è¡¨ç¤ºå°‡è¢«å­˜å„²ä»¥ä¾¿åœ¨æ¨ç†éç¨‹ä¸­ä½¿ç”¨ã€‚

* **æ–‡æª”å°å…¥ Ingesting documents**: æ–‡æª”åŠ è¼‰å™¨æ˜¯æ–¹ä¾¿çš„åŒ…è£å™¨ï¼Œå¯ä»¥è™•ç†å¤šç¨®æ ¼å¼ï¼š PDF, JSON, HTML, Markdown, ç­‰ã€‚ å®ƒå€‘é‚„å¯ä»¥ç›´æ¥å¾ä¸€äº›æ•¸æ“šåº«å’ŒAPIï¼ˆGitHub, Reddit, Google Drive, ç­‰ï¼‰æª¢ç´¢æ•¸æ“šã€‚
* **æ–‡æª”æ‹†åˆ† Splitting documents**: æ–‡æœ¬æ‹†åˆ†å™¨å°‡æ–‡æª”æ‹†åˆ†æˆè¼ƒå°çš„ã€èªç¾©ä¸Šæœ‰æ„ç¾©çš„ç‰‡æ®µã€‚é€šå¸¸æœ€å¥½ä¸è¦åœ¨nå€‹å­—ç¬¦å¾Œæ‹†åˆ†æ–‡æœ¬ï¼Œè€Œæ˜¯æŒ‰ç…§æ¨™é¡Œæˆ–éè¿´åœ°æ‹†åˆ†ï¼Œä¸¦é™„å¸¶ä¸€äº›é¡å¤–çš„å…ƒæ•¸æ“šã€‚
* **åµŒå…¥æ¨¡å‹ Embedding models**: åµŒå…¥æ¨¡å‹å°‡æ–‡æœ¬è½‰æ›ç‚ºå‘é‡è¡¨ç¤ºã€‚é€™å…è¨±å°èªè¨€é€²è¡Œæ›´æ·±å…¥ã€æ›´ç´°è†©çš„ç†è§£ï¼Œé€™å°æ–¼é€²è¡Œèªç¾©æœç´¢è‡³é—œé‡è¦ã€‚
* **å‘é‡æ•¸æ“šåº« Vector databases**: å‘é‡æ•¸æ“šåº«ï¼ˆå¦‚ [Chroma](https://www.trychroma.com/), [Pinecone](https://www.pinecone.io/), [Milvus](https://milvus.io/), [FAISS](https://faiss.ai/), [Annoy](https://github.com/spotify/annoy), ç­‰ï¼‰å°ˆç‚ºå„²å­˜åµŒå…¥å‘é‡è€Œè¨­è¨ˆã€‚å®ƒå€‘æ”¯æ´åŸºæ–¼å‘é‡ç›¸ä¼¼æ€§æœ‰æ•ˆæª¢ç´¢èˆ‡æŸ¥è©¢æœ€ç›¸ä¼¼çš„æ•¸æ“šã€‚

ğŸ“š ** åƒè€ƒè³‡æ–™**:
* [LangChain - Text splitters](https://python.langchain.com/docs/modules/data_connection/document_transformers/): LangChainå¯¦ç¾çš„ä¸åŒæ–‡æœ¬æ‹†åˆ†å™¨åˆ—è¡¨ã€‚
* [Sentence Transformers library](https://www.sbert.net/): æµè¡Œçš„åµŒå…¥æ¨¡å‹åº«ã€‚
* [MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard): åµŒå…¥æ¨¡å‹çš„æ’è¡Œæ¦œã€‚
* [The Top 5 Vector Databases](https://www.datacamp.com/blog/the-top-5-vector-databases) by Moez Ali: æœ€ä½³å’Œæœ€æµè¡Œçš„å‘é‡æ•¸æ“šåº«æ¯”è¼ƒã€‚

---
### 3. Retrieval Augmented Generation æª¢ç´¢å¢å¼·ç”Ÿæˆ

å€ŸåŠ© RAGï¼ŒLLMs å¯ä»¥å¾è³‡æ–™åº«ä¸­æª¢ç´¢ä¸Šä¸‹æ–‡æ–‡æª”ï¼Œä»¥æé«˜ç­”æ¡ˆçš„æº–ç¢ºæ€§ã€‚RAG æ˜¯ä¸€ç¨®ç„¡éœ€ä»»ä½•å¾®èª¿å³å¯å¢å¼·æ¨¡å‹çŸ¥è­˜çš„æµè¡Œæ–¹æ³•ã€‚

* **Orchestrators å”ä½œå™¨**: Orchestrators å”ä½œå™¨ (å¦‚ [LangChain](https://python.langchain.com/docs/get_started/introduction), [LlamaIndex](https://docs.llamaindex.ai/en/stable/), [FastRAG](https://github.com/IntelLabs/fastRAG), ç­‰ï¼‰æ˜¯æµè¡Œçš„æ¡†æ¶ï¼Œç”¨æ–¼å°‡æ‚¨çš„ LLM èˆ‡å·¥å…·ã€è³‡æ–™åº«ã€è¨˜æ†¶é«”ç­‰é€£æ¥èµ·ä¾†ä¸¦å¢å¼·ä»–å€‘çš„èƒ½åŠ›ã€‚
* **Retrievers æª¢ç´¢å™¨**: ä½¿ç”¨è€…æŒ‡ä»¤æœªé‡å°æª¢ç´¢é€²è¡Œæœ€ä½³åŒ–ã€‚å¯ä»¥æ‡‰ç”¨ä¸åŒçš„æŠ€è¡“ï¼ˆä¾‹å¦‚ï¼Œå¤šæŸ¥è©¢æª¢ç´¢å™¨ã€ [HyDE](https://arxiv.org/abs/2212.10496), ç­‰ï¼‰ä¾†é‡æ–°è¡¨è¿°/æ“´å±•å®ƒå€‘ä¸¦æé«˜æ•ˆèƒ½ã€‚
* **è¨˜æ†¶**: ç‚ºäº†è¨˜ä½å…ˆå‰çš„èªªæ˜å’Œç­”æ¡ˆï¼ŒLLM å’Œ ChatGPT ç­‰èŠå¤©æ©Ÿå™¨äººæœƒå°‡æ­¤æ­·å²è¨˜éŒ„æ·»åŠ åˆ°å…¶ä¸Šä¸‹æ–‡è¦–çª—ä¸­ã€‚æ­¤ç·©è¡å€å¯ä»¥é€éåŒ¯ç¸½ï¼ˆä¾‹å¦‚ï¼Œä½¿ç”¨è¼ƒå°çš„ LLMï¼‰ã€å‘é‡å„²å­˜ + RAG ç­‰ä¾†æ”¹é€²ã€‚
* **è©•ä¼°**: æˆ‘å€‘éœ€è¦è©•ä¼°æ–‡ä»¶æª¢ç´¢ï¼ˆä¸Šä¸‹æ–‡ç²¾ç¢ºåº¦å’Œå¬å›ç‡ï¼‰å’Œç”Ÿæˆéšæ®µï¼ˆå¯ä¿¡åº¦å’Œç­”æ¡ˆç›¸é—œæ€§ï¼‰ã€‚å¯ä»¥ä½¿ç”¨ [Ragas](https://github.com/explodinggradients/ragas/tree/main) å’Œ [DeepEval](https://github.com/confident-ai/deepeval)å·¥å…·é€²è¡Œç°¡åŒ–ã€‚

ğŸ“š **åƒè€ƒè³‡æ–™**:
* [Llamaindex - High-level concepts](https://docs.llamaindex.ai/en/stable/getting_started/concepts.html): å»ºé€  RAG ç®¡é“æ™‚éœ€è¦äº†è§£çš„ä¸»è¦æ¦‚å¿µã€‚
* [Pinecone - Retrieval Augmentation](https://www.pinecone.io/learn/series/langchain/langchain-retrieval-augmentation/): æª¢ç´¢å¢å¼·æµç¨‹æ¦‚è¿°ã€‚
* [LangChain - Q&A with RAG](https://python.langchain.com/docs/use_cases/question_answering/quickstart): å»ºç«‹å…¸å‹ RAG ç®¡é“çš„é€æ­¥æ•™å­¸ã€‚
* [LangChain - Memory types](https://python.langchain.com/docs/modules/memory/types/): ä¸åŒé¡å‹è¨˜æ†¶é«”åŠå…¶ç›¸é—œç”¨é€”çš„æ¸…å–®ã€‚
* [RAG pipeline - Metrics](https://docs.ragas.io/en/stable/concepts/metrics/index.html): ç”¨æ–¼è©•ä¼° RAG ç®¡é“çš„ä¸»è¦æŒ‡æ¨™çš„æ¦‚è¿°ã€‚
---
### 4. é€²éš RAG

ç¾å¯¦æ‡‰ç”¨ç¨‹å¼å¯èƒ½éœ€è¦è¤‡é›œçš„ç®¡é“ï¼ŒåŒ…æ‹¬ SQL æˆ–åœ–å½¢è³‡æ–™åº«ï¼Œä»¥åŠè‡ªå‹•é¸æ“‡ç›¸é—œå·¥å…·å’Œ APIã€‚é€™äº›å…ˆé€²æŠ€è¡“å¯ä»¥æ”¹é€²åŸºæº–è§£æ±ºæ–¹æ¡ˆä¸¦æä¾›é™„åŠ åŠŸèƒ½ã€‚

* **æŸ¥è©¢å»ºæ§‹**: å„²å­˜åœ¨å‚³çµ±æ•¸æ“šåº«ä¸­çš„çµæ§‹åŒ–æ•¸æ“šéœ€è¦ç‰¹å®šçš„æŸ¥è©¢èªè¨€ï¼Œå¦‚SQLã€Cypherã€å…ƒæ•¸æ“šç­‰ã€‚æˆ‘å€‘å¯ä»¥ç›´æ¥å°‡ç”¨æˆ¶æŒ‡ä»¤ç¿»è­¯æˆæŸ¥è©¢ï¼Œé€šéæŸ¥è©¢å»ºæ§‹ä¾†å­˜å–æ•¸æ“šã€‚
* **ä»£ç†èˆ‡å·¥å…·**: ä»£ç†é€éè‡ªå‹•é¸æ“‡æœ€ç›¸é—œçš„å·¥å…·ä¾†å¢å¼·LLMsçš„å›ç­”èƒ½åŠ›ã€‚é€™äº›å·¥å…·å¯ä»¥åƒä½¿ç”¨Googleæˆ–Wikipediaé‚£éº¼ç°¡å–®ï¼Œæˆ–è€…åƒPythonè§£é‡‹å™¨æˆ–Jiraé€™æ¨£è¤‡é›œã€‚
* **å¾Œè™•ç†**: è™•ç†è¼¸å…¥åˆ°LLMçš„æœ€å¾Œä¸€æ­¥ã€‚å®ƒé€šéé‡æ–°æ’åºã€[RAGèåˆ](https://github.com/Raudaschl/rag-fusion)å’Œåˆ†é¡ä¾†å¢å¼·æª¢ç´¢æ–‡æª”çš„ç›¸é—œæ€§å’Œå¤šæ¨£æ€§ã€‚

ğŸ“š **åƒè€ƒè³‡æ–™**:
* [LangChain - Query ConstructionæŸ¥è©¢å»ºæ§‹](https://blog.langchain.dev/query-construction/): é—œæ–¼ä¸åŒé¡å‹æŸ¥è©¢å»ºæ§‹çš„åšå®¢æ–‡ç« .
* [LangChain - SQL](https://python.langchain.com/docs/use_cases/qa_structured/sql): æ•™ç¨‹ï¼Œä»‹ç´¹å¦‚ä½•åˆ©ç”¨LLMsèˆ‡SQLæ•¸æ“šåº«äº’å‹•ï¼ŒåŒ…æ‹¬Text-to-SQLå’Œå¯é¸çš„SQLä»£ç†ã€‚
* [Pinecone - LLM agents(ä»£ç†)](https://www.pinecone.io/learn/series/langchain/langchain-agents/): ä»‹ç´¹ä¸åŒé¡å‹çš„ä»£ç†å’Œå·¥å…·ã€‚
* [LLM Powered Autonomous Agents(ä»£ç†)](https://lilianweng.github.io/posts/2023-06-23-agent/) by Lilian Weng: é—œæ–¼LLMä»£ç†çš„æ›´ç†è«–æ€§æ–‡ç« ã€‚
* [LangChain - OpenAI's RAG](https://blog.langchain.dev/applying-openai-rag/): æ¦‚è¿°OpenAIä½¿ç”¨çš„RAGç­–ç•¥ï¼ŒåŒ…æ‹¬å¾Œè™•ç†ã€‚

---
### 5. Inference optimization æ¨ç†å„ªåŒ–

æ–‡æœ¬ç”Ÿæˆæ˜¯ä¸€å€‹æˆæœ¬é«˜æ˜‚çš„éç¨‹ï¼Œéœ€è¦æ˜‚è²´çš„ç¡¬é«”è¨­å‚™ã€‚é™¤äº†é‡åŒ–ä¹‹å¤–ï¼Œé‚„æœ‰å„ç¨®æŠ€è¡“è¢«æå‡ºä»¥æœ€å¤§åŒ–ååé‡ä¸¦é™ä½æ¨è«–æˆæœ¬ã€‚

* **Flash Attention é–ƒå­˜æ³¨æ„åŠ›**: å„ªåŒ–æ³¨æ„åŠ›æ©Ÿåˆ¶ï¼Œå°‡å…¶è¤‡é›œæ€§å¾äºŒæ¬¡æ–¹è®Šæˆç·šæ€§ä»¥åŠ å¿«è¨“ç·´å’Œæ¨è«–é€Ÿåº¦ã€‚
* **Key-value cache éµå€¼å¿«å–**: è«‹å¤šäº†è§£éµå€¼å¿«å–ä»¥åŠå¤šæŸ¥è©¢æ³¨æ„åŠ›ï¼ˆ[Multi-Query Attention](https://arxiv.org/abs/1911.02150) (MQA)ï¼‰å’Œ(åˆ†çµ„æŸ¥è©¢æ³¨æ„åŠ›[Grouped-Query Attention](https://arxiv.org/abs/2305.13245) (GQA)ï¼‰å¸¶ä¾†çš„æ”¹é€²ã€‚
* **Speculative decoding æŠ•æ©Ÿè§£ç¢¼**: ä½¿ç”¨å°å‹æ¨¡å‹ç”¢ç”Ÿè‰ç¨¿ï¼Œç„¶å¾Œç”±æ›´å¤§çš„æ¨¡å‹å¯©æ ¸ï¼Œä»¥åŠ å¿«æ–‡æœ¬ç”Ÿæˆé€Ÿåº¦ã€‚

ğŸ“š **åƒè€ƒè³‡æ–™**:
* [GPU Inference](https://huggingface.co/docs/transformers/main/en/perf_infer_gpu_one) by Hugging Face: è§£é‡‹å¦‚ä½•åœ¨GPUä¸Šå„ªåŒ–æ¨è«–.
* [LLM Inference](https://www.databricks.com/blog/llm-inference-performance-engineering-best-practices) by Databricks: å¯¦éš›é‹ä½œä¸­å„ªåŒ–LLMæ¨è«–çš„æœ€ä½³å¯¦è¸ã€‚
* [Optimizing LLMs for Speed and Memory](https://huggingface.co/docs/transformers/main/en/llm_tutorial_optimization) by Hugging Face: è§£é‡‹ä¸‰ç¨®ä¸»è¦çš„é€Ÿåº¦å’Œè¨˜æ†¶é«”å„ªåŒ–æŠ€è¡“ï¼Œå³é‡åŒ–ã€é–ƒå­˜æ³¨æ„åŠ›å’Œæ¶æ§‹å‰µæ–°ã€‚
* [Assisted Generation](https://huggingface.co/blog/assisted-generation) by Hugging Face: HFç‰ˆæœ¬çš„æŠ•æ©Ÿè§£ç¢¼ï¼Œé€™æ˜¯ä¸€ç¯‡æœ‰è¶£çš„åšå®¢æ–‡ç« ï¼Œä»‹ç´¹äº†å®ƒçš„å·¥ä½œåŸç†åŠå…¶å¯¦ç¾ä»£ç¢¼ã€‚

---
### 6. Deploying LLMs éƒ¨ç½²å¤§å‹èªè¨€æ¨¡å‹

åœ¨å¤§è¦æ¨¡éƒ¨ç½²å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ˜¯ä¸€é …å·¥ç¨‹å£¯èˆ‰ï¼Œå¯èƒ½éœ€è¦å¤šå€‹GPUé›†ç¾¤ã€‚åœ¨å…¶ä»–æƒ…æ™¯ä¸‹ï¼Œæ¼”ç¤ºå’Œæœ¬åœ°æ‡‰ç”¨å¯ä»¥æ›´ç°¡å–®çš„å¯¦ç¾é‹ä½œã€‚

* **Local deployment æœ¬åœ°éƒ¨ç½²**: éš±ç§æ˜¯é–‹æºLLMsç›¸å°æ–¼ç§æœ‰LLMsçš„ä¸€å€‹é‡è¦å„ªå‹¢ã€‚ æœ¬åœ°LLMæœå‹™å™¨ ([LM Studio](https://lmstudio.ai/), [Ollama](https://ollama.ai/), [oobabooga](https://github.com/oobabooga/text-generation-webui), [kobold.cpp](https://github.com/LostRuins/koboldcpp), ç­‰ï¼‰åˆ©ç”¨é€™ä¸€å„ªå‹¢ç‚ºæœ¬åœ°æ‡‰ç”¨æä¾›å‹•åŠ›ã€‚ 
* **Demo deployment æ¼”ç¤ºéƒ¨ç½²**:åƒ [Gradio](https://www.gradio.app/) å’Œ [Streamlit](https://docs.streamlit.io/) é€™æ¨£çš„æ¡†æ¶æœ‰åŠ©æ–¼åŸå‹æ‡‰ç”¨çš„é–‹ç™¼å’Œæ¼”ç¤ºçš„åˆ†äº«ã€‚æ‚¨ä¹Ÿå¯ä»¥è¼•é¬†åœ°åœ¨ç·šä¸Šéƒ¨ç½²ï¼Œä¾‹å¦‚ä½¿ç”¨ [Hugging Face Spaces](https://huggingface.co/spaces)ã€‚ 
* **Server deployment æœå‹™å™¨éƒ¨ç½²**: å¤§è¦æ¨¡éƒ¨ç½²LLMséœ€è¦é›²ç«¯ (è©³è¦‹ [SkyPilot](https://skypilot.readthedocs.io/en/latest/)) æˆ–å…§éƒ¨éƒ¨ç½²çš„åŸºç¤è¨­æ–½ï¼Œä¸¦ç¶“å¸¸åˆ©ç”¨å„ªåŒ–çš„æ–‡æœ¬ç”Ÿæˆæ¡†æ¶ï¼Œå¦‚ [TGI](https://github.com/huggingface/text-generation-inference), [vLLM](https://github.com/vllm-project/vllm/tree/main)ç­‰ã€‚
* **Edge deployment é‚Šç·£(ä¸­ä½ç®—åŠ›)éƒ¨ç½²**: åœ¨å—é™ç’°å¢ƒä¸­ï¼Œé«˜æ€§èƒ½æ¡†æ¶å¦‚ [MLC LLM](https://github.com/mlc-ai/mlc-llm) å’Œ [mnn-llm](https://github.com/wangzhaode/mnn-llm/blob/master/README_en.md) å¯ä»¥åœ¨ç¶²é ç€è¦½å™¨ã€Androidå’ŒiOSä¸­éƒ¨ç½²LLMã€‚

ğŸ“š **åƒè€ƒè³‡æ–™**:
* [Streamlit - Build a basic LLM app](https://docs.streamlit.io/knowledge-base/tutorials/build-conversational-apps): ä½¿ç”¨Streamlitå‰µå»ºé¡ä¼¼ChatGPTçš„åŸºç¤æ‡‰ç”¨çš„æ•™å­¸ã€‚
* [HF LLM Inference Container](https://huggingface.co/blog/sagemaker-huggingface-llm): Dä½¿ç”¨Hugging Faceçš„æ¨è«–å®¹å™¨åœ¨Amazon SageMakerä¸Šéƒ¨ç½²LLMsã€‚
* [PhilschmidÂ blog](https://www.philschmid.de/) by Philipp Schmid: é—œæ–¼ä½¿ç”¨Amazon SageMakeréƒ¨ç½²LLMçš„é«˜è³ªé‡æ–‡ç« é›†ã€‚
* [Optimizing latence å„ªåŒ–å»¶é²](https://hamel.dev/notes/llm/inference/03_inference.html) by Hamel Husain:æ¯”è¼ƒTGIã€vLLMã€CTranslate2å’Œmlcåœ¨ååé‡å’Œå»¶é²æ–¹é¢çš„æ€§èƒ½ã€‚

---
### 7. Securing LLMs 

é™¤äº†èˆ‡è»Ÿé«”ç›¸é—œçš„å‚³çµ±å®‰å…¨å•é¡Œå¤–ï¼Œç”±æ–¼è¨“ç·´å’Œæç¤ºçš„æ–¹å¼ï¼Œå¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMsï¼‰é‚„æœ‰ç‰¹å®šçš„å¼±é»ã€‚

* **Prompt hacking æç¤ºè©æ”»æ“Š**: èˆ‡æç¤ºå·¥ç¨‹ç›¸é—œçš„æŠ€è¡“ç•¥æœ‰ä¸åŒï¼Œæç¤ºè©æ³¨å…¥ï¼ˆä½¿ç”¨é¡å¤–æŒ‡ä»¤ä»¥åŠ«æŒæ¨¡å‹çš„ç­”æ¡ˆï¼‰ã€æ•¸æ“š/æç¤ºæ´©æ¼ï¼ˆæª¢ç´¢å…¶åŸå§‹æ•¸æ“š/æç¤ºï¼‰å’Œè¶Šç„ï¼ˆè£½ä½œæç¤ºè©ä»¥ç¹éå®‰å…¨ç‰¹æ€§ï¼‰éƒ½ç®—åœ¨æ­¤ç¯„åœå…§ã€‚
* **Backdoors å¾Œé–€**:  æ”»æ“Šå‘é‡å¯ä»¥é‡å°è¨“ç·´æ•¸æ“šæœ¬èº«ï¼Œé€šéæ±¡æŸ“è¨“ç·´æ•¸æ“šï¼ˆä¾‹å¦‚ï¼Œä½¿ç”¨éŒ¯èª¤ä¿¡æ¯ï¼‰æˆ–å‰µå»ºå¾Œé–€ï¼ˆè§¸ç™¼å™¨åœ¨æ¨è«–æœŸé–“ç§˜å¯†çš„æ”¹è®Šæ¨¡å‹è¡Œç‚ºï¼‰ã€‚
* **Defensive measures é˜²ç¦¦æªæ–½**: ä¿è­·æ‚¨çš„LLMæ‡‰ç”¨ç¨‹åºçš„æœ€ä½³æ–¹å¼æ˜¯å°é€™äº›æ¼æ´é€²è¡Œæ¸¬è©¦ (e.g., ä¾‹å¦‚ï¼Œä½¿ç”¨ç´…éšŠæ¸¬è©¦å’Œåƒ[garak](https://github.com/leondz/garak/)é€™æ¨£çš„æª¢æŸ¥ ) ä¸¦åœ¨å¯¦éš›çš„ç’°å¢ƒä¸­è§€å¯Ÿå®ƒå€‘ï¼ˆä½¿ç”¨åƒ[langfuse](https://github.com/langfuse/langfuse)é€™æ¨£çš„æ¡†æ¶ï¼‰ã€‚

ğŸ“š **References**:
* [OWASP LLM Top 10](https://owasp.org/www-project-top-10-for-large-language-model-applications/) by HEGO Wiki: LLMæ‡‰ç”¨ç¨‹åºä¸­10å€‹æœ€åš´é‡çš„æ¼æ´æ¸…å–®ã€‚
* [Prompt Injection Primer](https://github.com/jthack/PIPE) by Joseph Thacker: å°ˆé–€é‡å°å·¥ç¨‹å¸«çš„æç¤ºæ³¨å…¥çŸ­æŒ‡å—ã€‚
* [LLM Security](https://llmsecurity.net/) by [@llm_sec](https://twitter.com/llm_sec): èˆ‡LLMå®‰å…¨ç›¸é—œçš„å»£æ³›è³‡æºåˆ—è¡¨ã€‚
* [Red teaming LLMs](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/red-teaming) by Microsoft: é—œæ–¼å¦‚ä½•åŸ·è¡ŒLLMç´…éšŠæ¸¬è©¦çš„æŒ‡å—ã€‚

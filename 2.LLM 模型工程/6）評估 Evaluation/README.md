
### 6. è©•ä¼° Evaluation

è©•ä¼°å¤§å‹èªè¨€æ¨¡å‹(LLMs)æ˜¯æµç¨‹ä¸­ä¸€å€‹è¢«ä½ä¼°çš„éƒ¨åˆ†ï¼Œå› ç‚ºè©•ä¼°é€™ä¸€å€‹éç¨‹è€—æ™‚ä¸”ç›¸å°å¯é æ€§è¼ƒä½ã€‚ä½ çš„ä¸‹æ¸¸ä»»å‹™æ‡‰è©²æŒ‡æ˜ä½ æƒ³è¦è©•ä¼°çš„å…§å®¹ï¼Œä½†è¨˜å¾—å¤å¾·å“ˆç‰¹å®šå¾‹(Goodhart's law)æåˆ°çš„ï¼šâ€œç•¶ä¸€å€‹è¡¡é‡æŒ‡æ¨™è®Šæˆäº†ç›®æ¨™ï¼Œå®ƒå°±ä¸å†æ˜¯ä¸€å€‹å¥½çš„è¡¡é‡æŒ‡æ¨™ã€‚â€
* ç°¡ä»‹èˆ‡å…¥é–€ï¼š
    * [Evaluating and Debugging Generative AI Models Using Weights and Biases](https://www.deeplearning.ai/short-courses/evaluating-debugging-generative-ai//): Deeplearning AI çš„çŸ­èª²ç¨‹ï¼Œé©åˆå¿«é€Ÿå…¥é–€ã€‚
    * [LLM Evaluation å¦‚ä½•è¯„ä¼°ä¸€ä¸ªå¤§æ¨¡å‹ï¼Ÿ](https://zhuanlan.zhihu.com/p/644373658): åˆ¥äººçš„å¿ƒå¾—ï¼Œå¯ä»¥åƒè€ƒä¸‹ã€‚

* **å‚³çµ±æŒ‡æ¨™ Traditional metrics**: åƒå›°æƒ‘åº¦(perplexity)å’ŒBLEUåˆ†æ•¸é€™æ¨£çš„æŒ‡æ¨™ä¸å†åƒä»¥å‰é‚£æ¨£å—æ­¡è¿ï¼Œå› ç‚ºåœ¨å¤§å¤šæ•¸æƒ…æ³ä¸‹å®ƒå€‘æ˜¯æœ‰ç¼ºé™·çš„ã€‚ä½†äº†è§£å®ƒå€‘ä»¥åŠå®ƒå€‘é©ç”¨çš„æƒ…å¢ƒä»ç„¶å¾ˆé‡è¦ã€‚
    * [å›ºå®šé•·åº¦è¼¸å…¥(æœ‰æœ€å¤§è¼¸å…¥é™åˆ¶)æ¨¡å‹çš„å›°æƒ‘åº¦](https://huggingface.co/docs/transformers/perplexity) by Hugging Face: å›°æƒ‘åº¦(perplexity)çš„æ¦‚è¿°ï¼Œä¸¦ä½¿ç”¨ Transformer åº«å¯¦ç¾äº†å®ƒçš„ç¨‹å¼ç¢¼ã€‚
    * [BLEU ä½¿ç”¨é¢¨éšª](https://towardsdatascience.com/evaluating-text-output-in-nlp-bleu-at-your-own-risk-e8609665a213) by Rachael Tatman: BLEU åˆ†æ•¸åŠå…¶è¨±å¤šå•é¡Œçš„æ¦‚è¿°ï¼Œä¸¦æä¾›äº†ç¤ºä¾‹ã€‚
* **é€šç”¨åŸºæº– General benchmarks**: åŸºæ–¼èªè¨€æ¨¡å‹è©•ä¼°å·¥å…·ç®± [Language Model Evaluation Harness](https://github.com/EleutherAI/lm-evaluation-harness)ï¼ŒOpen LLMæ’è¡Œæ¦œ [Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard) æ˜¯ç”¨æ–¼é€šç”¨å¤§å‹èªè¨€æ¨¡å‹ï¼ˆå¦‚ChatGPTï¼‰çš„ä¸»è¦åŸºæº–ã€‚é‚„æœ‰å…¶ä»–å—æ­¡è¿çš„åŸºæº–ï¼Œå¦‚[BigBench](https://github.com/google/BIG-bench), [MT-Bench](https://arxiv.org/abs/2306.05685)ç­‰ã€‚
    * [å¤§å‹èªè¨€æ¨¡å‹è©•ä¼°èª¿æŸ¥](https://arxiv.org/abs/2307.03109) by Chang et al.: é—œæ–¼è©•ä¼°ä»€éº¼ã€åœ¨å“ªè£¡è©•ä¼°ä»¥åŠå¦‚ä½•è©•ä¼°çš„ç¶œåˆæ€§è«–æ–‡ã€‚
* **ä»»å‹™ç‰¹å®šåŸºæº– Task-specific benchmarks**: å¦‚æ‘˜è¦ã€ç¿»è­¯å’Œå•ç­”ç­‰ä»»å‹™æœ‰å°ˆé–€çš„åŸºæº–ã€æŒ‡æ¨™ç”šè‡³å­é ˜åŸŸï¼ˆé†«ç™‚ã€é‡‘èç­‰ï¼‰ï¼Œä¾‹å¦‚ç”¨æ–¼ç”Ÿç‰©é†«å­¸å•ç­” [PubMedQA](https://pubmedqa.github.io/)ã€‚
* **äººé¡è©•ä¼° Human evaluation**: æœ€å¯é çš„è©•ä¼°æ˜¯ç”¨æˆ¶çš„æ¥å—åº¦æˆ–ç”±äººé¡æ‰€åšçš„æ¯”è¼ƒã€‚å¦‚æœä½ æƒ³çŸ¥é“ä¸€å€‹æ¨¡å‹è¡¨ç¾å¾—å¦‚ä½•ï¼Œæœ€ç°¡å–®ä½†æœ€ç¢ºå®šçš„æ–¹å¼å°±æ˜¯è‡ªå·±ä½¿ç”¨å®ƒã€‚

ğŸ“š **åƒè€ƒæ–‡ç»**:
* [èŠå¤©æ©Ÿå™¨äººæ’è¡Œæ¦œ](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard) by lmsys: åŸºæ–¼äººé¡æ¯”è¼ƒçš„é€šç”¨å¤§å‹èªè¨€æ¨¡å‹çš„Eloè©•åˆ†ã€‚

### 5. Reinforcement Learning from Human Feedback RLHF (æ ¹æ“šäººé¡å›é¥‹é€²è¡Œå¼·åŒ–å­¸ç¿’)

ç¶“éç›£ç£å¾®èª¿å¾Œï¼ŒRLHF æ˜¯ç”¨ä¾†ä½¿ LLM çš„ç­”æ¡ˆèˆ‡äººé¡æœŸæœ›ä¿æŒä¸€è‡´çš„ä¸€å€‹æ­¥é©Ÿã€‚é€™å€‹æƒ³æ³•æ˜¯å¾äººé¡ï¼ˆæˆ–äººå·¥ï¼‰å›é¥‹ä¸­å­¸ç¿’åå¥½ï¼Œé€™å¯ç”¨æ–¼æ¸›å°‘åè¦‹ã€å¯©æŸ¥æ¨¡å‹æˆ–ä½¿å®ƒå€‘ä»¥æ›´æœ‰ç”¨çš„æ–¹å¼è¡Œäº‹ã€‚å®ƒæ¯” SFT æ›´è¤‡é›œï¼Œä¸¦ä¸”é€šå¸¸è¢«è¦–ç‚ºå¯é¸é …ä¹‹ä¸€ã€‚
* ç°¡ä»‹èˆ‡å…¥é–€ï¼š
    * [An Introduction to Training LLMs using RLHF](https://wandb.ai/ayush-thakur/Intro-RLAIF/reports/An-Introduction-to-Training-LLMs-Using-Reinforcement-Learning-From-Human-Feedback-RLHF---VmlldzozMzYyNjcy) by Ayush Thakur: é€™è§£é‡‹äº†ç‚ºä»€éº¼ RLHF å°æ–¼æ¸›å°‘å¤§èªè¨€æ¨¡å‹çš„åè¦‹å’Œæé«˜ç¸¾æ•ˆæ˜¯å¯å–çš„ã€‚
    * [Illustration RLHF](https://huggingface.co/blog/rlhf) by Hugging Face: RLHF ç°¡ä»‹ï¼ŒåŒ…æ‹¬çå‹µæ¨¡å‹è¨“ç·´å’Œå¼·åŒ–å­¸ç¿’å¾®èª¿.
    * [RLHF from Deeplearning.ai](https://www.deeplearning.ai/short-courses/finetuning-large-language-models/):  Deeplearning.ai çš„RLHFçŸ­èª²ç¨‹ï¼Œé©åˆå¿«é€Ÿå…¥é–€ã€‚

* **åå¥½è³‡æ–™é›†**: é€™äº›è³‡æ–™é›†é€šå¸¸åŒ…å«å…·æœ‰æŸç¨®æ’åçš„å¤šå€‹ç­”æ¡ˆï¼Œé€™ä½¿å¾—å®ƒå€‘æ¯”æŒ‡ä»¤è³‡æ–™é›†æ›´é›£ç”¢ç”Ÿ.
    * [StackLLaMA](https://huggingface.co/blog/stackllama) by Hugging Face: ä½¿ç”¨ Transformer å‡½å¼åº«æœ‰æ•ˆåœ°å°‡ LLaMA æ¨¡å‹èˆ‡ RLHF å°é½Šçš„æ•™å­¸.
* [**è¿‘ç«¯ç­–ç•¥æœ€ä½³åŒ–**](https://arxiv.org/abs/1707.06347): æ­¤æ¼”ç®—æ³•åˆ©ç”¨çå‹µæ¨¡å‹ä¾†é æ¸¬çµ¦å®šæ–‡å­—æ˜¯å¦è¢«äººé¡æ’åè¼ƒé«˜ã€‚ç„¶å¾Œä½¿ç”¨è©²é æ¸¬ä¾†æœ€ä½³åŒ– SFT æ¨¡å‹ï¼Œä¸¦æ ¹æ“š KL æ•£åº¦é€²è¡Œçæ‡²ã€‚
* **[ç›´æ¥åå¥½å„ªåŒ–](https://arxiv.org/abs/2305.18290)**: DPO é€éå°‡å…¶é‡æ–°å®šç¾©ç‚ºåˆ†é¡å•é¡Œä¾†ç°¡åŒ–æµç¨‹ã€‚å®ƒä½¿ç”¨åƒè€ƒæ¨¡å‹è€Œä¸æ˜¯çå‹µæ¨¡å‹ï¼ˆç„¡éœ€è¨“ç·´ï¼‰ï¼Œä¸¦ä¸”åªéœ€è¦ä¸€å€‹è¶…åƒæ•¸ï¼Œä½¿å…¶æ›´åŠ ç©©å®šå’Œé«˜æ•ˆã€‚

ğŸ“š **åƒè€ƒè³‡æ–™**:
* [LLM Training: RLHF and Its Alternatives](https://substack.com/profile/27393275-sebastian-raschka-phd) by Sebastian Rashcka: RLHF æµç¨‹å’Œ RLAIF ç­‰æ›¿ä»£æ–¹æ¡ˆçš„æ¦‚è¿°.
* [Fine-tune Mistral-7b with DPO](https://huggingface.co/blog/dpo-trl):ä½¿ç”¨ DPO å¾®èª¿ Mistral-7b æ¨¡å‹ä¸¦é‡ç¾[NeuralHermes-2.5](https://huggingface.co/mlabonne/NeuralHermes-2.5-Mistral-7B) çš„æ•™å­¸.
* [[RL] Fine-Tuning Language Models from Human Preferences (RLHF) è«–æ–‡ç­†è¨˜-ChatGPTéŠæˆè¡“](https://hackmd.io/@YungHuiHsu/Sy5Ug7iV6)
* [è¯¦è§£å¤§æ¨¡å‹RLHFè¿‡ç¨‹ï¼ˆé…ä»£ç è§£è¯»ï¼‰](https://zhuanlan.zhihu.com/p/624589622)
* [LLMåŸºçŸ³ï¼šRLHFåŠå…¶æ›¿ä»£æŠ€æœ¯](https://zhuanlan.zhihu.com/p/682683518)
* [å›¾è§£å¤§æ¨¡å‹RLHFç³»åˆ—ä¹‹ï¼šäººäººéƒ½èƒ½çœ‹æ‡‚çš„PPOåŸç†ä¸æºç è§£è¯»](https://zhuanlan.zhihu.com/p/677607581)
* [RLAIFç»†èŠ‚åˆ†äº«&ä¸ªäººæƒ³æ³•](https://zhuanlan.zhihu.com/p/657436655)

### 4. ç›£ç£å¾®èª¿ (Supervised Fine-Tuning)

é è¨“ç·´æ¨¡å‹åƒ…é‡å°ä¸‹ä¸€å€‹æ¨™è¨˜(next-token)é æ¸¬ä»»å‹™é€²è¡Œè¨“ç·´ï¼Œé€™å°±æ˜¯ç‚ºä»€éº¼å®ƒå€‘ä¸æ˜¯æœ‰ç”¨çš„åŠ©æ‰‹ã€‚SFT å…è¨±æ‚¨èª¿æ•´å®ƒå€‘ä»¥å›æ‡‰æŒ‡ä»¤ã€‚æ­¤å¤–ï¼Œå®ƒå…è¨±æ‚¨æ ¹æ“šä»»ä½•è³‡æ–™ï¼ˆç§äººè³‡æ–™ã€GPT-4 ç„¡æ³•çœ‹åˆ°çš„è³‡æ–™ç­‰ï¼‰å¾®èª¿æ‚¨çš„æ¨¡å‹ä¸¦ä½¿ç”¨å®ƒï¼Œè€Œç„¡éœ€æ”¯ä»˜ OpenAI ç­‰ API çš„è²»ç”¨ã€‚
* ç°¡ä»‹è·Ÿæ•™å­¸ï¼š
    * [ç”¨äººè©±è¬›è§£å¾®èª¿æŠ€è¡“](https://www.zhihu.com/zvideo/1723348624463994881)ï¼šè«‹åªå°ˆæ³¨æŠ€è¡“ã€‚
    * [Finetuning Large Language Models](https://www.deeplearning.ai/short-courses/finetuning-large-language-models/): Deeplearning.ai çš„å¾®èª¿æŠ€è¡“çŸ­èª²ç¨‹ï¼Œé©åˆå¿«é€Ÿå…¥é–€ã€‚
* **å…¨å¾®èª¿**: å…¨å¾®èª¿æ˜¯æŒ‡è¨“ç·´æ¨¡å‹ä¸­çš„æ‰€æœ‰åƒæ•¸ ( å°±æ˜¯æ¨¡å‹è¨“ç·´ï¼Œåªæ˜¯è³‡æ–™é‡ä¸å¤š )ã€‚é€™ä¸æ˜¯ä¸€ç¨®æœ‰æ•ˆçš„æŠ€è¡“ï¼Œä½†å®ƒæœƒç”¢ç”Ÿç¨å¾®å¥½ä¸€é»çš„çµæœ.
    * [The Novice's LLM Training Guide](https://rentry.org/llm-training) by Alpin: æ¦‚è¿°å¾®èª¿ LLM æ™‚è¦è€ƒæ…®çš„ä¸»è¦æ¦‚å¿µå’Œåƒæ•¸.
* [**LoRA**](https://arxiv.org/abs/2106.09685): ä¸€ç¨®åŸºæ–¼ä½éšé©é…å™¨(low-rank adapters)çš„é«˜æ•ˆåƒæ•¸å¾®èª¿æŠ€è¡“ï¼ˆPEFTï¼‰ã€‚æˆ‘å€‘ä¸è¨“ç·´æ‰€æœ‰åƒæ•¸ï¼Œè€Œæ˜¯åªè¨“ç·´é€™äº›é©é…å™¨(adapters)ã€‚
    * [LoRA insights](https://lightning.ai/pages/community/lora-insights/) by Sebastian Raschka: æœ‰é—œ LoRA ä»¥åŠå¦‚ä½•é¸æ“‡æœ€ä½³åƒæ•¸çš„å¯¦ç”¨è¦‹è§£.
    * [Fine-Tune Your Own Llama 2 Model](https://mlabonne.github.io/blog/posts/Fine_Tune_Your_Own_Llama_2_Model_in_a_Colab_Notebook.html): æœ‰é—œå¦‚ä½•ä½¿ç”¨ Hugging Face åº«å¾®èª¿ Llama 2 æ¨¡å‹çš„å¯¦ä½œæ•™å­¸.
    * [Padding Large Language Models](https://towardsdatascience.com/padding-large-language-models-examples-with-llama-2-199fb10df8ff) by Benjamin Marie: ç‚ºå› æœLLMs(causal LLMs)å¡«å……è¨“ç·´ç¯„ä¾‹çš„æœ€ä½³å¯¦è¸ 
* [**QLoRA**](https://arxiv.org/abs/2305.14314): å¦ä¸€å€‹åŸºæ–¼ LoRA çš„ PEFTï¼Œå®ƒé‚„å°‡æ¨¡å‹çš„æ¬Šé‡é‡åŒ–ç‚º 4 bitsï¼Œä¸¦å¼•å…¥åˆ†é å„ªåŒ–å™¨ä¾†ç®¡ç†è¨˜æ†¶é«”å³°å€¼ã€‚å°‡å…¶èˆ‡[Unsloth](https://github.com/unslothai/unsloth)çµåˆä½¿ç”¨ï¼Œå¯ä»¥åœ¨å…è²»çš„ Colab ç­†è¨˜æœ¬ä¸Šé‹è¡Œã€‚
* **[Axolotl](https://github.com/OpenAccess-AI-Collective/axolotl)**: ä¸€ç¨®ç”¨æˆ¶å‹å¥½ä¸”åŠŸèƒ½å¼·å¤§çš„å¾®èª¿å·¥å…·ï¼Œç”¨æ–¼è¨±å¤šæœ€å…ˆé€²çš„é–‹æºæ¨¡å‹ã€‚
    * [A Beginner's Guide to LLM Fine-Tuning](https://mlabonne.github.io/blog/posts/A_Beginners_Guide_to_LLM_Finetuning.html): æœ‰é—œå¦‚ä½•ä½¿ç”¨ Axolotl å¾®èª¿ CodeLlama æ¨¡å‹çš„æ•™å­¸.
* [**DeepSpeed**](https://www.deepspeed.ai/): é‡å°å¤š GPU å’Œå¤šç¯€é»è¨­å®šçš„ LLM çš„é«˜æ•ˆé è¨“ç·´å’Œå¾®èª¿ï¼ˆåœ¨ Axolotl ä¸­å¯¦ç¾ï¼‰ã€‚
    
ğŸ“š **åƒè€ƒè³‡æ–™**:
* [ä¸‡å­—é•¿æ–‡ä¹‹æç¤ºå­¦ä¹ å’Œå¾®è°ƒå¤§æ¨¡å‹ï¼ˆPrompt Learning & Prompt Tuningï¼‰](https://zhuanlan.zhihu.com/p/670039833)
* [å¤§æ¨¡å‹å¾®è°ƒæ€»ç»“](https://www.zhihu.com/tardis/zm/art/627642632?source_id=1003)
* [Finetuning Large Language Models çš„èª²ç¨‹ç­†è¨˜](https://hackmd.io/@YungHuiHsu/HJ6AT8XG6)

---
